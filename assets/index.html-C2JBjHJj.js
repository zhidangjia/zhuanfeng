import{_ as t,c as a,a as n,o as r}from"./app-DlfcJbGw.js";const o={};function i(p,e){return r(),a("div",null,e[0]||(e[0]=[n('<p>经常访问的一个金融投资专家在展望2026年时提到： 2026年目前在预期的元年，</p><ul><li>自动驾驶元年</li><li>液冷元年</li><li>国产HBM元年</li><li>端侧AI元年</li><li>固态电池元年</li><li>AI应用元年</li><li>量子计算元年</li><li>存算一体芯片商用元年</li><li>类脑计算元年</li><li>低空经济元年</li><li>商业航天元年</li><li>人型机器人元年</li><li>硅光元年</li><li>可控核聚变元年</li></ul><p>总之就是各种元年，让人眼花缭乱，股民又有很多知识要恶补了。当然了，我肯定不是来科普上述概念的，作为我最关注的人工智能领域，在过去的2025年其实也有不少新的元年，我借此也尝试总结几个本人感兴趣的点。</p><h2 id="一、推理-reasoning-元年" tabindex="-1"><a class="header-anchor" href="#一、推理-reasoning-元年"><span>一、推理（Reasoning）元年</span></a></h2><p>2024年9月，OpenAI凭借o1与o1-mini模型，正式开启了一场以“推理”为核心的革命——这场革命也被称为推理规模扩展（inference-scaling），或**基于可验证奖励的强化学习（RLVR）**革命。2025年初，该公司又推出o3、o3-mini及o4-mini模型，进一步加码这一技术方向。自此，推理能力几乎成为所有主流AI实验室模型的标志性特征。对这一技术突破重要性的理解，我们来看看安德烈·卡帕西（Andrej Karpathy）的<a href="https://karpathy.bearblog.dev/year-in-review-2025/" target="_blank" rel="noopener noreferrer">解释</a>：</p><blockquote><p>通过在多个环境中（例如数学题/代码谜题），利用自动可验证的奖励对大语言模型（LLM）进行训练，模型会自发形成人类眼中类似“推理”的策略——它们学会将问题拆解为中间计算步骤，还掌握了多种反复推敲以解决问题的策略（相关案例可参考 DeepSeek R1 论文）。</p></blockquote><blockquote><p>实践证明，RLVR 训练具备极高的<strong>性价比（能力/成本比）</strong>，这也消耗了原本计划用于预训练的大量计算资源。因此，2025年大语言模型的能力进步，很大程度上取决于各实验室对这一新阶段技术红利的挖掘。总体来看，2025年的模型规模与此前相近，但 RL（强化学习）的训练时长大幅增加。</p></blockquote><p>2025年，所有知名 AI 实验室至少都发布了一款推理模型。部分实验室推出了支持<strong>推理/非推理双模式</strong>的混合模型。如今，许多API模型都配备了调节旋钮，可针对特定提示词调整推理的深度。而推理能力真正的突破，在于<strong>工具调用</strong>。具备工具调用能力的推理模型，能够规划多步骤任务、执行任务，并基于结果持续推理，从而更新计划以更好地达成目标。一个显著成果是，<strong>AI辅助搜索如今真正可用</strong>。此前，将搜索引擎与大语言模型对接的效果一直不尽如人意，但现在，即便是更复杂的研究问题，我也常常能通过ChatGPT中的“GPT-5思考模式”得到解答。推理模型在<strong>代码生成与调试</strong>方面也表现卓越。推理机制让模型能够从一个错误出发，逐步排查代码库的多个层级，定位问题根源。我发现，只要推理模型具备读取和执行代码的能力，即便是面对庞大复杂的代码库，最棘手的漏洞也能被优秀的推理模型诊断出来。</p><h2 id="二、智能体-ai-agents-元年" tabindex="-1"><a class="header-anchor" href="#二、智能体-ai-agents-元年"><span>二、智能体（AI agents）元年</span></a></h2><p>当推理能力与工具调用能力相结合，你将得到智能体（AI agents）。</p><p>整个2025年，所有人都在谈论智能体，每个使用“智能体”这个术语的人，给出的定义似乎都略有不同。在我看来，智能体就是一种通过循环调用工具来达成目标的大语言模型（LLM）系统。智能体的两大突破性应用领域是编码和搜索。深度研究模式，即让大语言模型负责收集信息，耗时15分钟以上为你生成一份详细报告，在今年也风靡一时。我就曾尝试用豆包研究过一个学术课题，确实可以写出一份有模有样的研究报告，但是很多细节需要优化，比如引用地址的时效性等问题。GPT-5的思考模式也是一种智能体模式，而且运作效果也很不错。</p><h2 id="三、编码智能体-coding-agents-元年" tabindex="-1"><a class="header-anchor" href="#三、编码智能体-coding-agents-元年"><span>三、编码智能体（coding agents）元年</span></a></h2><p>2025年最具影响力的事件发生在2月 ——Anthropic 低调发布了 Claude Code。说它低调，是因为它甚至没有单独的博客文章！Anthropic将Claude Code的发布，作为其宣布Claude 3.7 Sonnet的博客文章中的第二项内容。Claude Code是我所说的编码智能体最典型的例子，这类大语言模型系统能够编写代码、执行代码、检查结果，然后进一步迭代优化。2025年，各大实验室都推出了自己的命令行界面（CLI）编码智能体：Claude Code、Codex CLI、Gemini CLI、通义千问代码（Qwen Code）、Mistral Vibe，独立于厂商的选项包括GitHub Copilot CLI、Amp、OpenCode、OpenHands CLI 和 Pi。Zed、VS Code 和 Cursor 等集成开发环境（IDE）也在编码智能体的集成方面投入了大量精力。</p><p>我第一次接触编码智能体模式，还是下半年自己写的一个小项目：不用任何复杂的前端框架（如react），用纯html+css+js的模式，去定制一个企业网站。最大的难点就是设计稿要求精准还原，并且需要有各种动效。当然了，我肯定不是精通前端的人，顶多算个了解前端，css更只是略知一二。我Cursor和Trae都用了，最终因为费用等问题，还是选择了Trae。用过后只想说：以前做不了的项目，现在确实轻松，除了要珍惜自己的使用额度外，其他没毛病。最大的难点反而是一开始的官网设计图怎么转成html代码，figma make用了下，效果也不是很好。</p><h2 id="四、氛围编程-vibe-coding-元年" tabindex="-1"><a class="header-anchor" href="#四、氛围编程-vibe-coding-元年"><span>四、氛围编程（vibe coding）元年</span></a></h2><p>今年2月，安德烈・卡帕西（Andrej Karpathy）在一条推文中创造了 “氛围编程”（vibe coding）这个术语：</p><blockquote><p>我发现了一种全新的编程方式，称之为 “氛围编程”。在这种模式下，你完全沉浸于氛围之中，拥抱指数级提升的效率，甚至可以忘掉代码本身的存在。这种方式之所以可行，是因为大语言模型（比如搭载Sonnet模型的 Cursor Composer）已经变得过于强大。我现在还会用SuperWhisper和Composer语音交互，几乎不用碰键盘。我会提一些极其琐碎的需求，比如 “把侧边栏的内边距减少一半”，因为我懒得自己去找对应的代码。我总是直接 “全部接受” 模型生成的内容，再也不看代码差异对比了。遇到错误提示时，我直接复制粘贴过去，不加任何说明，通常这样就能解决问题。代码的复杂程度已经超出了我平时的理解范围，要搞懂它得花不少时间仔细研读。有时候模型修不好bug，我就换种方式绕开，或者让它随机修改，直到问题消失。这种方式用来做周末随手的一次性项目还不错，而且过程特别有意思。我确实在做一个项目或网页应用，但这已经算不上真正的编程了。我只是看看效果、说说话、运行一下程序，再复制粘贴点东西，大部分时候都能正常工作。</p></blockquote><p>这个概念的核心在于 <strong>“忘掉代码本身的存在”</strong>。氛围编程代表了一种全新、有趣的软件原型开发方式，仅通过提示词就能实现大部分功能正常工作的效果。但很多人把氛围编程当成了一个万能标签，将所有涉及大语言模型的编程工作都归为此类，我认为有些绝对。大多数情况是专业工程师借助AI辅助构建生产级软件的工作模式。</p><h2 id="五、mcp元年" tabindex="-1"><a class="header-anchor" href="#五、mcp元年"><span>五、MCP元年</span></a></h2><p>2024年11月，Anthropic推出了 <strong>模型上下文协议（Model Context Protocol，MCP）</strong> 规范，将其作为一种用于在不同大语言模型（LLM）中集成工具调用的开放标准。2025年初，该协议的受欢迎程度呈爆发式增长。5月曾出现这样一个节点：OpenAI、Anthropic和Mistral三家公司在短短八天内，相继推出了对MCP的API级支持！MCP的理念本身足够合理，但其极高的采用率却让我颇感意外。我认为这归根结底是时机问题：MCP 的发布恰逢模型终于在工具调用方面变得成熟可靠，以至于许多人似乎将对MCP的支持误认为是模型使用工具的先决条件。</p><p>自从我深度使用Trae及同类工具后，就几乎不再使用MCP了。Anthropic自身似乎也在今年晚些时候意识到了这一点，推出了出色的Skills（技能）机制。MCP涉及Web服务器和复杂的JSON负载，而一个Skill只是文件夹中的一个Markdown文件，还可选择性地附带一些可执行脚本。随后在11月，Anthropic发布了<a href="https://www.anthropic.com/engineering/code-execution-with-mcp" target="_blank" rel="noopener noreferrer">《通过 MCP 执行代码：构建更高效的智能体》</a>。文中描述了一种让编码智能体生成代码来调用MCP的方式，这种方式规避了原始规范带来的大量上下文开销。</p><p>12月初，MCP被捐赠给了新成立的智能体人工智能基金会（Agentic AI Foundation）。</p><h2 id="六、上下文工程元年" tabindex="-1"><a class="header-anchor" href="#六、上下文工程元年"><span>六、上下文工程元年</span></a></h2><p>上下文工程（context engineering）这一术语近来开始受到关注，被视为提示工程（prompt engineering）更优的替代概念。</p><p>以下是Shopify首席执行官托比・吕特克（Tobi Lutke）发布的一条相关推文<a href="https://twitter.com/tobi/status/1935533422589399127" target="_blank" rel="noopener noreferrer">示例</a>：</p><blockquote><p>相比 “提示工程”，我更喜欢 “上下文工程” 这个说法。它更准确地描述了这项核心技能：为任务提供所有必要语境，使大语言模型（LLM）具备合理解决该任务的能力，这是一门艺术。</p></blockquote><p>近期，安德烈・卡帕西（Andrej Karpathy）也进一步强调了这一<a href="https://twitter.com/karpathy/status/1937902205765607626" target="_blank" rel="noopener noreferrer">观点</a>：</p><blockquote><p>强烈支持用 “上下文工程” 取代 “提示工程”。人们通常将 “提示” 与日常使用大语言模型时给出的简短任务描述联系在一起。但在所有工业级大语言模型应用中，上下文工程是一门精妙的艺术与科学，它需要在语境窗口中，为下一步操作填充恰到好处的信息。说它是科学，是因为做好这件事需要涵盖任务描述与说明、少样本示例、检索增强生成（RAG）、相关（可能是多模态的）数据、工具、状态与历史记录、信息压缩…… 要做好这些工作难度极大。说它是艺术，则是因为这需要凭借对大语言模型 “心智模式” 的直觉判断来指导实践……</p></blockquote><p>常见的上下文工程的方法有：offload（转移策略）、reduce（压缩策略）、retrieve（检索策略）、isolate（隔离策略）、cache（缓存的机制）等。</p>',29)]))}const s=t(o,[["render",i]]),c=JSON.parse('{"path":"/article/the-year-of-2025/","title":"2025，元年的一年","lang":"zh-CN","frontmatter":{"title":"2025，元年的一年","createTime":"2026/01/01 16:15:00","permalink":"/article/the-year-of-2025/","excerpt":"各种元年，让人眼花缭乱。我最关注的人工智能领域，在过去的2025年其实也有不少新的元年，我借此也尝试总结几个本人感兴趣的点。","outline":[2,3],"cover":"/img/各种元年.jpg","tags":["技术专栏"],"description":"经常访问的一个金融投资专家在展望2026年时提到： 2026年目前在预期的元年， 自动驾驶元年 液冷元年 国产HBM元年 端侧AI元年 固态电池元年 AI应用元年 量子计算元年 存算一体芯片商用元年 类脑计算元年 低空经济元年 商业航天元年 人型机器人元年 硅光元年 可控核聚变元年 总之就是各种元年，让人眼花缭乱，股民又有很多知识要恶补了。当然了，我肯...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"2025，元年的一年\\",\\"image\\":[\\"https://zhuanfeng.netlify.app/img/各种元年.jpg\\"],\\"dateModified\\":null,\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://zhuanfeng.netlify.app/article/the-year-of-2025/"}],["meta",{"property":"og:site_name","content":"朱岸峰的深度思考与分享"}],["meta",{"property":"og:title","content":"2025，元年的一年"}],["meta",{"property":"og:description","content":"经常访问的一个金融投资专家在展望2026年时提到： 2026年目前在预期的元年， 自动驾驶元年 液冷元年 国产HBM元年 端侧AI元年 固态电池元年 AI应用元年 量子计算元年 存算一体芯片商用元年 类脑计算元年 低空经济元年 商业航天元年 人型机器人元年 硅光元年 可控核聚变元年 总之就是各种元年，让人眼花缭乱，股民又有很多知识要恶补了。当然了，我肯..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://zhuanfeng.netlify.app/img/各种元年.jpg"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:src","content":"https://zhuanfeng.netlify.app/img/各种元年.jpg"}],["meta",{"name":"twitter:image:alt","content":"2025，元年的一年"}],["meta",{"property":"article:tag","content":"技术专栏"}]]},"readingTime":{"minutes":10.05,"words":3016},"git":{},"autoDesc":true,"filePathRelative":"技术专栏/2025，元年的一年.md","headers":[],"categoryList":[{"id":"9742da","sort":10003,"name":"技术专栏"}]}');export{s as comp,c as data};
